//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_100a
.address_size 64

	// .globl	matmul_kernel_make_tensor_desciptor // -- Begin function matmul_kernel_make_tensor_desciptor
.extern .shared .align 16 .b8 global_smem[];
                                        // @matmul_kernel_make_tensor_desciptor
.visible .entry matmul_kernel_make_tensor_desciptor(
	.param .u64 .ptr .global .align 1 matmul_kernel_make_tensor_desciptor_param_0,
	.param .u64 .ptr .global .align 1 matmul_kernel_make_tensor_desciptor_param_1,
	.param .u64 .ptr .global .align 1 matmul_kernel_make_tensor_desciptor_param_2,
	.param .u32 matmul_kernel_make_tensor_desciptor_param_3,
	.param .u32 matmul_kernel_make_tensor_desciptor_param_4,
	.param .u32 matmul_kernel_make_tensor_desciptor_param_5,
	.param .u64 .ptr .global .align 1 matmul_kernel_make_tensor_desciptor_param_6
)
.reqntid 128
{
	.reg .pred 	%p<154>;
	.reg .b32 	%r<592>;
	.reg .b64 	%rd<145>;
	.loc	1 6 0                           // matmul.py:6:0
$L__func_begin0:
	.loc	1 6 0                           // matmul.py:6:0

// %bb.0:
	ld.param.b64 	%rd13, [matmul_kernel_make_tensor_desciptor_param_0];
$L__tmp0:
	.loc	1 6 0                           // matmul.py:6
	mov.u32 	%r1, %tid.x;
	ld.param.b64 	%rd31, [matmul_kernel_make_tensor_desciptor_param_1];
	setp.lt.u32 	%p1, %r1, 32;
	ld.param.b64 	%rd49, [matmul_kernel_make_tensor_desciptor_param_2];
	mov.b32 	%r62, global_smem;
	// begin inline asm
	@%p1 tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [%r62], 64;
	// end inline asm
	ld.param.b32 	%r68, [matmul_kernel_make_tensor_desciptor_param_3];
	bar.sync 	0;
	ld.param.b32 	%r67, [matmul_kernel_make_tensor_desciptor_param_4];
	ld.shared.b32 	%r561, [global_smem];
	ld.param.b32 	%r75, [matmul_kernel_make_tensor_desciptor_param_5];
	bar.sync 	0;
	ld.param.b64 	%rd70, [matmul_kernel_make_tensor_desciptor_param_6];
	// begin inline asm
	@%p1 tcgen05.relinquish_alloc_permit.cta_group::1.sync.aligned;
	// end inline asm
	.loc	1 14 26                         // matmul.py:14:26
	mov.u32 	%r217, %ctaid.x;
	.loc	1 15 26                         // matmul.py:15:26
	mov.u32 	%r218, %ctaid.y;
	.loc	1 18 8                          // matmul.py:18:8
	mov.u32 	%r219, %ctaid.z;
	mov.u32 	%r220, %nctaid.x;
	mov.u32 	%r221, %nctaid.y;
	mad.lo.s32 	%r222, %r219, %r221, %r218;
	mad.lo.s32 	%r223, %r222, %r220, %r217;
	mul.lo.s32 	%r224, %r223, 384;
	cvt.s64.s32 	%rd71, %r224;
	add.s64 	%rd27, %rd70, %rd71;
	mul.wide.s32 	%rd20, %r67, 4;
	and.b32 	%r3, %r1, 127;
	setp.lt.u32 	%p3, %r3, 32;
	shl.b32 	%r225, %r3, 2;
	add.s32 	%r63, %r62, %r225;
	mov.b32 	%r591, 0;
	// begin inline asm
	@%p3 st.shared.b32 [ %r63 + 0 ], %r591;
	// end inline asm
	bar.warp.sync 	-1;
	setp.eq.s32 	%p145, %r3, 0;
	cvt.u64.u32 	%rd12, %r62;
	// begin inline asm
	@%p145 tensormap.replace.tile.global_address.shared::cta.b1024.b64 [ %rd12 + 0 ], %rd13;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.rank.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1;
	// end inline asm
	mov.b32 	%r65, 32;
	// begin inline asm
	@%p145 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0, %r65;
	// end inline asm
	mov.b32 	%r66, 128;
	// begin inline asm
	@%p145 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1, %r66;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0, %r67;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1, %r68;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.global_stride.shared::cta.b1024.b64 [ %rd12 + 0 ], 0x0, %rd20;
	// end inline asm
	mov.b32 	%r69, 1;
	// begin inline asm
	@%p145 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0, %r69;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1, %r69;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.elemtype.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x7;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.interleave_layout.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.swizzle_mode.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x3;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.fill_mode.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p3 tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned [ %rd27 + 0 ], [ %rd12 + 0 ], 0x80;
	// end inline asm
	// begin inline asm
	@%p3 fence.proxy.tensormap::generic.acquire.gpu [ %rd27 + 0 ], 0x80;
	@%p3 cp.async.bulk.commit_group ;
	@%p3 cp.async.bulk.wait_group.read 0 ;
	// end inline asm
	bar.sync 	0;
	cvta.global.u64 	%rd66, %rd27;
	.loc	1 24 8                          // matmul.py:24:8
	add.s32 	%r226, %r224, 128;
	cvt.s64.s32 	%rd72, %r226;
	add.s64 	%rd45, %rd70, %rd72;
	mul.wide.s32 	%rd56, %r75, 4;
	bar.sync 	0;
	// begin inline asm
	@%p3 st.shared.b32 [ %r63 + 0 ], %r591;
	// end inline asm
	bar.warp.sync 	-1;
	// begin inline asm
	@%p145 tensormap.replace.tile.global_address.shared::cta.b1024.b64 [ %rd12 + 0 ], %rd31;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.rank.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0, %r65;
	// end inline asm
	mov.b32 	%r74, 64;
	// begin inline asm
	@%p145 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1, %r74;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0, %r75;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1, %r67;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.global_stride.shared::cta.b1024.b64 [ %rd12 + 0 ], 0x0, %rd56;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0, %r69;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1, %r69;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.elemtype.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x7;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.interleave_layout.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.swizzle_mode.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x3;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.fill_mode.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p3 tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned [ %rd45 + 0 ], [ %rd12 + 0 ], 0x80;
	// end inline asm
	// begin inline asm
	@%p3 fence.proxy.tensormap::generic.acquire.gpu [ %rd45 + 0 ], 0x80;
	@%p3 cp.async.bulk.commit_group ;
	@%p3 cp.async.bulk.wait_group.read 0 ;
	// end inline asm
	bar.sync 	0;
	cvta.global.u64 	%rd67, %rd45;
	.loc	1 30 8                          // matmul.py:30:8
	add.s32 	%r227, %r224, 256;
	cvt.s64.s32 	%rd73, %r227;
	add.s64 	%rd63, %rd70, %rd73;
	bar.sync 	0;
	// begin inline asm
	@%p3 st.shared.b32 [ %r63 + 0 ], %r591;
	// end inline asm
	bar.warp.sync 	-1;
	// begin inline asm
	@%p145 tensormap.replace.tile.global_address.shared::cta.b1024.b64 [ %rd12 + 0 ], %rd49;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.rank.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0, %r65;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1, %r66;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0, %r75;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1, %r68;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.global_stride.shared::cta.b1024.b64 [ %rd12 + 0 ], 0x0, %rd56;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0, %r69;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x1, %r69;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.elemtype.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x7;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.interleave_layout.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.swizzle_mode.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x3;
	// end inline asm
	// begin inline asm
	@%p145 tensormap.replace.tile.fill_mode.shared::cta.b1024.b32 [ %rd12 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p3 tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned [ %rd63 + 0 ], [ %rd12 + 0 ], 0x80;
	// end inline asm
	// begin inline asm
	@%p3 fence.proxy.tensormap::generic.acquire.gpu [ %rd63 + 0 ], 0x80;
	@%p3 cp.async.bulk.commit_group ;
	@%p3 cp.async.bulk.wait_group.read 0 ;
	// end inline asm
	bar.sync 	0;
$L__tmp1:
	.loc	2 40 22                         // standard.py:40:22 @[ matmul.py:37:30 ]
	add.s32 	%r4, %r67, 63;
$L__tmp2:
	.loc	1 38 33                         // matmul.py:38:33
	shl.b32 	%r559, %r217, 7;
	.loc	1 39 51                         // matmul.py:39:51
	shl.b32 	%r231, %r218, 6;
	.loc	1 40 32                         // matmul.py:40:32
	shr.u32 	%r232, %r1, 5;
	shfl.sync.idx.b32 	%r7, %r232, 0, 31, -1;
	shl.b32 	%r233, %r7, 21;
	and.b32 	%r234, %r233, 6291456;
	shl.b32 	%r235, %r7, 4;
	and.b32 	%r236, %r235, -64;
	add.s32 	%r237, %r234, %r561;
	add.s32 	%r557, %r237, %r236;
	mov.pred 	%p85, -1;
	// begin inline asm
	@%p85 tcgen05.st.sync.aligned.32x32b.x64.b32 [%r557 + 0], {%r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591, %r591};
	// end inline asm
	// begin inline asm
	tcgen05.wait::st.sync.aligned;
	// end inline asm
	bar.sync 	0;
	.loc	1 37 19                         // matmul.py:37:19
	add.s32 	%r590, %r62, 180256;
	// begin inline asm
	@%p145 mbarrier.init.shared::cta.b64 [%r590], 1;
	// end inline asm
	bar.sync 	0;
	add.s32 	%r153, %r62, 180264;
	// begin inline asm
	@%p145 mbarrier.init.shared::cta.b64 [%r153], 1;
	// end inline asm
	add.s32 	%r154, %r62, 180224;
	// begin inline asm
	@%p145 mbarrier.init.shared::cta.b64 [%r154], 1;
	// end inline asm
	bar.sync 	0;
	add.s32 	%r155, %r62, 180232;
	// begin inline asm
	@%p145 mbarrier.init.shared::cta.b64 [%r155], 1;
	// end inline asm
	bar.sync 	0;
	add.s32 	%r329, %r62, 180240;
	// begin inline asm
	@%p145 mbarrier.init.shared::cta.b64 [%r329], 1;
	// end inline asm
	setp.lt.s32 	%p70, %r4, 64;
	setp.gt.s32 	%p69, %r4, 63;
	bar.sync 	0;
	and.pred 	%p63, %p145, %p69;
	// begin inline asm
	@%p63 mbarrier.arrive.expect_tx.shared.b64 _, [%r154], 49152;
	// end inline asm
	.loc	1 38 24                         // matmul.py:38:24
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	bar.sync 	0;
	elect.sync 	%r238|%p71, -1;
	and.pred 	%p72, %p69, %p71;
	setp.lt.u32 	%p73, %r3, 64;
	and.pred 	%p64, %p73, %p72;
	and.b32 	%r239, %r7, 1;
	shl.b32 	%r9, %r239, 12;
	shl.b32 	%r240, %r239, 14;
	add.s32 	%r560, %r62, %r240;
	shl.b32 	%r159, %r239, 5;
	// begin inline asm
	@%p64 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r560], [%rd66, {%r159, %r559}], [%r154];
	// end inline asm
	.loc	1 39 24                         // matmul.py:39:24
	bar.sync 	0;
	elect.sync 	%r241|%p74, -1;
	and.pred 	%p75, %p69, %p74;
	and.pred 	%p65, %p73, %p75;
	shl.b32 	%r12, %r239, 11;
	add.s32 	%r242, %r62, 98304;
	shl.b32 	%r243, %r239, 13;
	add.s32 	%r162, %r242, %r243;
	or.b32 	%r558, %r159, %r231;
	// begin inline asm
	@%p65 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r162], [%rd67, {%r558, %r591}], [%r154];
	// end inline asm
	.loc	1 37 19                         // matmul.py:37:19
	setp.gt.s32 	%p76, %r4, 127;
	bar.sync 	0;
	and.pred 	%p66, %p145, %p76;
	// begin inline asm
	@%p66 mbarrier.arrive.expect_tx.shared.b64 _, [%r155], 49152;
	// end inline asm
	.loc	1 38 24                         // matmul.py:38:24
	bar.sync 	0;
	elect.sync 	%r244|%p77, -1;
	and.pred 	%p78, %p76, %p77;
	and.pred 	%p67, %p73, %p78;
	add.s32 	%r167, %r560, 32768;
	or.b32 	%r168, %r159, 64;
	// begin inline asm
	@%p67 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r167], [%rd66, {%r168, %r559}], [%r155];
	// end inline asm
	.loc	1 39 24                         // matmul.py:39:24
	bar.sync 	0;
	elect.sync 	%r245|%p79, -1;
	and.pred 	%p80, %p76, %p79;
	and.pred 	%p68, %p73, %p80;
	add.s32 	%r246, %r62, %r243;
	add.s32 	%r171, %r246, 114688;
	// begin inline asm
	@%p68 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r171], [%rd67, {%r558, %r74}], [%r155];
	// end inline asm
	.loc	1 37 19                         // matmul.py:37:19
	bar.sync 	0;
	// begin inline asm
	
{
	@!%p69 bra.uni skipWait;
	.reg .pred complete;
	waitLoop:
	mbarrier.try_wait.parity.shared.b64 complete, [%r154], %r591;
	@!complete bra.uni waitLoop;
	skipWait:
}

	// end inline asm
	.loc	1 39 24                         // matmul.py:39:24
	shl.b32 	%r247, %r1, 6;
	and.b32 	%r248, %r247, 2048;
	and.b32 	%r249, %r1, 24;
	shl.b32 	%r250, %r249, 3;
	or.b32 	%r251, %r248, %r250;
	and.b32 	%r252, %r1, 7;
	shl.b32 	%r253, %r252, 2;
	or.b32 	%r254, %r251, %r253;
	xor.b32 	%r255, %r254, %r249;
	and.b32 	%r256, %r1, 64;
	shr.u32 	%r257, %r256, 1;
	or.b32 	%r258, %r255, %r257;
	shr.u32 	%r259, %r256, 4;
	xor.b32 	%r15, %r258, %r259;
	shl.b32 	%r260, %r15, 2;
	add.s32 	%r181, %r242, %r260;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r177, %r178, %r179, %r180}, [%r181];
	// end inline asm
	xor.b32 	%r16, %r15, 256;
	shl.b32 	%r261, %r16, 2;
	add.s32 	%r186, %r242, %r261;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r182, %r183, %r184, %r185}, [%r186];
	// end inline asm
	xor.b32 	%r17, %r15, 512;
	shl.b32 	%r262, %r17, 2;
	add.s32 	%r191, %r242, %r262;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r187, %r188, %r189, %r190}, [%r191];
	// end inline asm
	xor.b32 	%r18, %r15, 768;
	shl.b32 	%r263, %r18, 2;
	add.s32 	%r196, %r242, %r263;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r192, %r193, %r194, %r195}, [%r196];
	// end inline asm
	xor.b32 	%r19, %r15, 1024;
	shl.b32 	%r264, %r19, 2;
	add.s32 	%r201, %r242, %r264;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r197, %r198, %r199, %r200}, [%r201];
	// end inline asm
	xor.b32 	%r20, %r15, 1280;
	shl.b32 	%r265, %r20, 2;
	add.s32 	%r206, %r242, %r265;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r202, %r203, %r204, %r205}, [%r206];
	// end inline asm
	xor.b32 	%r21, %r15, 1536;
	shl.b32 	%r266, %r21, 2;
	add.s32 	%r211, %r242, %r266;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r207, %r208, %r209, %r210}, [%r211];
	// end inline asm
	xor.b32 	%r22, %r15, 1792;
	shl.b32 	%r267, %r22, 2;
	add.s32 	%r216, %r242, %r267;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r212, %r213, %r214, %r215}, [%r216];
	// end inline asm
	shl.b32 	%r23, %r1, 7;
	and.b32 	%r268, %r23, 8064;
	shl.b32 	%r24, %r252, 4;
	or.b32 	%r269, %r268, %r24;
	or.b32 	%r25, %r269, %r259;
	add.s32 	%r270, %r62, 147456;
	add.s32 	%r271, %r270, %r25;
	st.shared.b32 	[%r271], %r177;
	st.shared.b32 	[%r271+8], %r178;
	st.shared.b32 	[%r271+8192], %r197;
	st.shared.b32 	[%r271+8200], %r198;
	xor.b32 	%r26, %r25, 16;
	add.s32 	%r272, %r270, %r26;
	st.shared.b32 	[%r272], %r179;
	st.shared.b32 	[%r272+8], %r180;
	st.shared.b32 	[%r272+8192], %r199;
	st.shared.b32 	[%r272+8200], %r200;
	xor.b32 	%r27, %r25, 32;
	add.s32 	%r273, %r270, %r27;
	st.shared.b32 	[%r273], %r182;
	st.shared.b32 	[%r273+8], %r183;
	st.shared.b32 	[%r273+8192], %r202;
	st.shared.b32 	[%r273+8200], %r203;
	xor.b32 	%r28, %r25, 48;
	add.s32 	%r274, %r270, %r28;
	st.shared.b32 	[%r274], %r184;
	st.shared.b32 	[%r274+8], %r185;
	st.shared.b32 	[%r274+8192], %r204;
	st.shared.b32 	[%r274+8200], %r205;
	xor.b32 	%r29, %r25, 64;
	add.s32 	%r275, %r270, %r29;
	st.shared.b32 	[%r275], %r187;
	st.shared.b32 	[%r275+8], %r188;
	st.shared.b32 	[%r275+8192], %r207;
	st.shared.b32 	[%r275+8200], %r208;
	xor.b32 	%r30, %r25, 80;
	add.s32 	%r276, %r270, %r30;
	st.shared.b32 	[%r276], %r189;
	st.shared.b32 	[%r276+8], %r190;
	st.shared.b32 	[%r276+8192], %r209;
	st.shared.b32 	[%r276+8200], %r210;
	xor.b32 	%r31, %r25, 96;
	add.s32 	%r277, %r270, %r31;
	st.shared.b32 	[%r277], %r192;
	st.shared.b32 	[%r277+8], %r193;
	st.shared.b32 	[%r277+8192], %r212;
	st.shared.b32 	[%r277+8200], %r213;
	xor.b32 	%r32, %r25, 112;
	add.s32 	%r278, %r270, %r32;
	st.shared.b32 	[%r278], %r194;
	st.shared.b32 	[%r278+8], %r195;
	st.shared.b32 	[%r278+8192], %r214;
	st.shared.b32 	[%r278+8200], %r215;
	.loc	1 40 32                         // matmul.py:40:32
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	bar.sync 	0;
	setp.ne.s32 	%p81, %r7, 0;
	or.pred 	%p82, %p70, %p81;
	@%p82 bra 	$L__BB0_2;
// %bb.1:
	elect.sync 	%r295|%p84, -1;
	bfe.u32 	%r297, %r62, 4, 14;
	cvt.u64.u32 	%rd91, %r297;
	or.b64 	%rd74, %rd91, 4611686293372403712;
	bfe.u32 	%r299, %r270, 4, 14;
	cvt.u64.u32 	%rd92, %r299;
	or.b64 	%rd75, %rd92, 4611686293338849280;
	mov.b32 	%r280, 135268624;
	mov.pred 	%p83, 0;
	// begin inline asm
	@%p84 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd74, %rd75, %r280, %p83;
	// end inline asm
	add.s32 	%r300, %r62, 32;
	bfe.u32 	%r301, %r300, 4, 14;
	cvt.u64.u32 	%rd93, %r301;
	or.b64 	%rd76, %rd93, 4611686293372403712;
	add.s32 	%r302, %r62, 147488;
	bfe.u32 	%r303, %r302, 4, 14;
	cvt.u64.u32 	%rd94, %r303;
	or.b64 	%rd77, %rd94, 4611686293338849280;
	// begin inline asm
	@%p84 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd76, %rd77, %r280, %p85;
	// end inline asm
	add.s32 	%r304, %r62, 64;
	bfe.u32 	%r305, %r304, 4, 14;
	cvt.u64.u32 	%rd95, %r305;
	or.b64 	%rd78, %rd95, 4611686293372403712;
	add.s32 	%r306, %r62, 147520;
	bfe.u32 	%r307, %r306, 4, 14;
	cvt.u64.u32 	%rd96, %r307;
	or.b64 	%rd79, %rd96, 4611686293338849280;
	// begin inline asm
	@%p84 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd78, %rd79, %r280, %p85;
	// end inline asm
	add.s32 	%r308, %r62, 96;
	bfe.u32 	%r309, %r308, 4, 14;
	cvt.u64.u32 	%rd97, %r309;
	or.b64 	%rd80, %rd97, 4611686293372403712;
	add.s32 	%r310, %r62, 147552;
	bfe.u32 	%r311, %r310, 4, 14;
	cvt.u64.u32 	%rd98, %r311;
	or.b64 	%rd81, %rd98, 4611686293338849280;
	// begin inline asm
	@%p84 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd80, %rd81, %r280, %p85;
	// end inline asm
	add.s32 	%r312, %r62, 16384;
	bfe.u32 	%r313, %r312, 4, 14;
	cvt.u64.u32 	%rd99, %r313;
	or.b64 	%rd82, %rd99, 4611686293372403712;
	add.s32 	%r314, %r62, 155648;
	bfe.u32 	%r315, %r314, 4, 14;
	cvt.u64.u32 	%rd100, %r315;
	or.b64 	%rd83, %rd100, 4611686293338849280;
	// begin inline asm
	@%p84 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd82, %rd83, %r280, %p85;
	// end inline asm
	add.s32 	%r316, %r62, 16416;
	bfe.u32 	%r317, %r316, 4, 14;
	cvt.u64.u32 	%rd101, %r317;
	or.b64 	%rd84, %rd101, 4611686293372403712;
	add.s32 	%r318, %r62, 155680;
	bfe.u32 	%r319, %r318, 4, 14;
	cvt.u64.u32 	%rd102, %r319;
	or.b64 	%rd85, %rd102, 4611686293338849280;
	// begin inline asm
	@%p84 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd84, %rd85, %r280, %p85;
	// end inline asm
	add.s32 	%r320, %r62, 16448;
	bfe.u32 	%r321, %r320, 4, 14;
	cvt.u64.u32 	%rd103, %r321;
	or.b64 	%rd86, %rd103, 4611686293372403712;
	add.s32 	%r322, %r62, 155712;
	bfe.u32 	%r323, %r322, 4, 14;
	cvt.u64.u32 	%rd104, %r323;
	or.b64 	%rd87, %rd104, 4611686293338849280;
	// begin inline asm
	@%p84 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd86, %rd87, %r280, %p85;
	// end inline asm
	add.s32 	%r324, %r62, 16480;
	bfe.u32 	%r325, %r324, 4, 14;
	cvt.u64.u32 	%rd105, %r325;
	or.b64 	%rd88, %rd105, 4611686293372403712;
	add.s32 	%r326, %r62, 155744;
	bfe.u32 	%r327, %r326, 4, 14;
	cvt.u64.u32 	%rd106, %r327;
	or.b64 	%rd89, %rd106, 4611686293338849280;
	// begin inline asm
	@%p84 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd88, %rd89, %r280, %p85;
	// end inline asm
	add.s32 	%r328, %r62, 180256;
	cvt.u64.u32 	%rd90, %r328;
	// begin inline asm
	@%p84 tcgen05.commit.cta_group::1.mbarrier::arrive::one.b64 [%rd90];
	// end inline asm
$L__BB0_2:
	.loc	1 37 19                         // matmul.py:37:19
	setp.gt.s32 	%p103, %r4, 191;
	setp.lt.s32 	%p104, %r4, 128;
	and.pred 	%p100, %p145, %p103;
	// begin inline asm
	@%p100 mbarrier.arrive.expect_tx.shared.b64 _, [%r329], 49152;
	// end inline asm
	.loc	1 38 24                         // matmul.py:38:24
	bar.sync 	0;
	elect.sync 	%r341|%p107, -1;
	and.pred 	%p108, %p103, %p107;
	and.pred 	%p101, %p73, %p108;
	shl.b32 	%r342, %r9, 2;
	add.s32 	%r343, %r62, %r342;
	add.s32 	%r330, %r343, 65536;
	or.b32 	%r331, %r159, 128;
	// begin inline asm
	@%p101 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r330], [%rd66, {%r331, %r559}], [%r329];
	// end inline asm
	.loc	1 39 24                         // matmul.py:39:24
	bar.sync 	0;
	elect.sync 	%r344|%p109, -1;
	and.pred 	%p110, %p103, %p109;
	and.pred 	%p102, %p73, %p110;
	shl.b32 	%r345, %r12, 2;
	add.s32 	%r346, %r62, %r345;
	add.s32 	%r334, %r346, 131072;
	// begin inline asm
	@%p102 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r334], [%rd67, {%r558, %r66}], [%r329];
	// end inline asm
	.loc	1 37 19                         // matmul.py:37:19
	@%p104 bra 	$L__BB0_7;
// %bb.3:                               // %.lr.ph
	.loc	1 0 19                          // matmul.py:0:19
	shr.s32 	%r228, %r4, 31;
	shr.u32 	%r229, %r228, 26;
	add.s32 	%r230, %r4, %r229;
	shr.s32 	%r5, %r230, 6;
	add.s32 	%r33, %r5, -3;
	add.s32 	%r353, %r62, 163840;
	add.s32 	%r34, %r353, %r25;
	add.s32 	%r35, %r353, %r26;
	add.s32 	%r36, %r353, %r27;
	add.s32 	%r37, %r353, %r28;
	add.s32 	%r38, %r353, %r29;
	add.s32 	%r39, %r353, %r30;
	add.s32 	%r40, %r353, %r31;
	add.s32 	%r41, %r353, %r32;
	bfe.u32 	%r354, %r353, 4, 14;
	cvt.u64.u32 	%rd109, %r354;
	or.b64 	%rd118, %rd109, 4611686293338849280;
	add.s32 	%r355, %r62, 163872;
	bfe.u32 	%r356, %r355, 4, 14;
	cvt.u64.u32 	%rd110, %r356;
	or.b64 	%rd120, %rd110, 4611686293338849280;
	add.s32 	%r357, %r62, 163904;
	bfe.u32 	%r358, %r357, 4, 14;
	cvt.u64.u32 	%rd111, %r358;
	or.b64 	%rd122, %rd111, 4611686293338849280;
	add.s32 	%r359, %r62, 163936;
	bfe.u32 	%r360, %r359, 4, 14;
	cvt.u64.u32 	%rd112, %r360;
	or.b64 	%rd124, %rd112, 4611686293338849280;
	add.s32 	%r361, %r62, 172032;
	bfe.u32 	%r362, %r361, 4, 14;
	cvt.u64.u32 	%rd113, %r362;
	or.b64 	%rd126, %rd113, 4611686293338849280;
	add.s32 	%r363, %r62, 172064;
	bfe.u32 	%r364, %r363, 4, 14;
	cvt.u64.u32 	%rd114, %r364;
	or.b64 	%rd128, %rd114, 4611686293338849280;
	add.s32 	%r365, %r62, 172096;
	bfe.u32 	%r366, %r365, 4, 14;
	cvt.u64.u32 	%rd115, %r366;
	or.b64 	%rd130, %rd115, 4611686293338849280;
	add.s32 	%r367, %r62, 172128;
	bfe.u32 	%r368, %r367, 4, 14;
	cvt.u64.u32 	%rd116, %r368;
	or.b64 	%rd132, %rd116, 4611686293338849280;
	.loc	1 37 19                         // matmul.py:37:19
	max.s32 	%r369, %r5, 2;
	add.s32 	%r583, %r62, 180256;
	add.s32 	%r42, %r369, -1;
	mov.b32 	%r587, 1;
	mov.b32 	%r586, 2;
	mov.b32 	%r582, 0;
	mov.b32 	%r581, 192;
	mov.b32 	%r584, %r582;
	mov.b32 	%r585, %r582;
	mov.b32 	%r588, %r582;
	mov.b32 	%r589, %r582;
	bra.uni 	$L__BB0_4;
$L__BB0_6:                              //   in Loop: Header=BB0_4 Depth=1
	.loc	1 37 19                         // matmul.py:37:19
	setp.lt.s32 	%p134, %r589, %r33;
	.loc	1 40 32                         // matmul.py:40:32
	// begin inline asm
	
{
	.reg .pred complete;
	waitLoop:
	mbarrier.try_wait.parity.shared.b64 complete, [%r583], %r582;
	@!complete bra.uni waitLoop;
}

	// end inline asm
	add.s32 	%r476, %r587, 1;
	setp.gt.s32 	%p137, %r476, 1;
	selp.b32 	%r587, 0, %r476, %p137;
	selp.b32 	%r477, 1, 0, %p137;
	xor.b32 	%r588, %r591, %r477;
	.loc	1 37 19                         // matmul.py:37:19
	add.s32 	%r478, %r586, 1;
	setp.gt.s32 	%p138, %r478, 2;
	selp.b32 	%r586, 0, %r478, %p138;
	shl.b32 	%r479, %r586, 3;
	add.s32 	%r481, %r62, %r479;
	add.s32 	%r471, %r481, 180224;
	and.pred 	%p131, %p145, %p134;
	// begin inline asm
	@%p131 mbarrier.arrive.expect_tx.shared.b64 _, [%r471], 49152;
	// end inline asm
	.loc	1 38 24                         // matmul.py:38:24
	shl.b32 	%r482, %r586, 15;
	bar.sync 	0;
	elect.sync 	%r483|%p139, -1;
	and.pred 	%p140, %p134, %p139;
	and.pred 	%p132, %p73, %p140;
	add.s32 	%r468, %r560, %r482;
	add.s32 	%r469, %r159, %r581;
	// begin inline asm
	@%p132 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r468], [%rd66, {%r469, %r559}], [%r471];
	// end inline asm
	.loc	1 39 24                         // matmul.py:39:24
	shl.b32 	%r484, %r586, 14;
	bar.sync 	0;
	elect.sync 	%r485|%p141, -1;
	and.pred 	%p142, %p134, %p141;
	and.pred 	%p133, %p73, %p142;
	add.s32 	%r472, %r162, %r484;
	// begin inline asm
	@%p133 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r472], [%rd67, {%r558, %r581}], [%r471];
	// end inline asm
	.loc	1 37 19                         // matmul.py:37:19
	add.s32 	%r589, %r589, 1;
	add.s32 	%r581, %r581, 64;
	setp.ne.s32 	%p143, %r42, %r589;
	mov.b32 	%r582, %r591;
	mov.b32 	%r583, %r590;
	@%p143 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_7;
$L__BB0_4:                              // =>This Inner Loop Header: Depth=1
	.loc	1 0 19                          // matmul.py:0:19
	mov.b32 	%r591, %r588;
	.loc	1 37 19                         // matmul.py:37:19
	add.s32 	%r412, %r585, 1;
	setp.gt.s32 	%p113, %r412, 2;
	selp.b32 	%r585, 0, %r412, %p113;
	selp.b32 	%r413, 1, 0, %p113;
	xor.b32 	%r584, %r584, %r413;
	shl.b32 	%r414, %r585, 3;
	add.s32 	%r416, %r62, %r414;
	add.s32 	%r370, %r416, 180224;
	bar.sync 	0;
	mov.pred 	%p114, -1;
	// begin inline asm
	
{
	@!%p114 bra.uni skipWait;
	.reg .pred complete;
	waitLoop:
	mbarrier.try_wait.parity.shared.b64 complete, [%r370], %r584;
	@!complete bra.uni waitLoop;
	skipWait:
}

	// end inline asm
	.loc	1 39 24                         // matmul.py:39:24
	shl.b32 	%r417, %r585, 14;
	add.s32 	%r418, %r62, %r417;
	add.s32 	%r419, %r418, 98304;
	add.s32 	%r376, %r419, %r260;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r372, %r373, %r374, %r375}, [%r376];
	// end inline asm
	add.s32 	%r381, %r419, %r261;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r377, %r378, %r379, %r380}, [%r381];
	// end inline asm
	add.s32 	%r386, %r419, %r262;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r382, %r383, %r384, %r385}, [%r386];
	// end inline asm
	add.s32 	%r391, %r419, %r263;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r387, %r388, %r389, %r390}, [%r391];
	// end inline asm
	add.s32 	%r396, %r419, %r264;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r392, %r393, %r394, %r395}, [%r396];
	// end inline asm
	add.s32 	%r401, %r419, %r265;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r397, %r398, %r399, %r400}, [%r401];
	// end inline asm
	add.s32 	%r406, %r419, %r266;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r402, %r403, %r404, %r405}, [%r406];
	// end inline asm
	add.s32 	%r411, %r419, %r267;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r407, %r408, %r409, %r410}, [%r411];
	// end inline asm
	st.shared.b32 	[%r34], %r372;
	st.shared.b32 	[%r34+8], %r373;
	st.shared.b32 	[%r34+8192], %r392;
	st.shared.b32 	[%r34+8200], %r393;
	st.shared.b32 	[%r35], %r374;
	st.shared.b32 	[%r35+8], %r375;
	st.shared.b32 	[%r35+8192], %r394;
	st.shared.b32 	[%r35+8200], %r395;
	st.shared.b32 	[%r36], %r377;
	st.shared.b32 	[%r36+8], %r378;
	st.shared.b32 	[%r36+8192], %r397;
	st.shared.b32 	[%r36+8200], %r398;
	st.shared.b32 	[%r37], %r379;
	st.shared.b32 	[%r37+8], %r380;
	st.shared.b32 	[%r37+8192], %r399;
	st.shared.b32 	[%r37+8200], %r400;
	st.shared.b32 	[%r38], %r382;
	st.shared.b32 	[%r38+8], %r383;
	st.shared.b32 	[%r38+8192], %r402;
	st.shared.b32 	[%r38+8200], %r403;
	st.shared.b32 	[%r39], %r384;
	st.shared.b32 	[%r39+8], %r385;
	st.shared.b32 	[%r39+8192], %r404;
	st.shared.b32 	[%r39+8200], %r405;
	st.shared.b32 	[%r40], %r387;
	st.shared.b32 	[%r40+8], %r388;
	st.shared.b32 	[%r40+8192], %r407;
	st.shared.b32 	[%r40+8200], %r408;
	st.shared.b32 	[%r41], %r389;
	st.shared.b32 	[%r41+8], %r390;
	st.shared.b32 	[%r41+8192], %r409;
	st.shared.b32 	[%r41+8200], %r410;
	.loc	1 37 19                         // matmul.py:37:19
	shl.b32 	%r428, %r587, 3;
	add.s32 	%r429, %r62, %r428;
	add.s32 	%r590, %r429, 180256;
	.loc	1 40 32                         // matmul.py:40:32
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	bar.sync 	0;
	@%p81 bra 	$L__BB0_6;
// %bb.5:                               //   in Loop: Header=BB0_4 Depth=1
	.loc	1 38 24                         // matmul.py:38:24
	shl.b32 	%r446, %r585, 15;
	add.s32 	%r448, %r62, %r446;
	.loc	1 40 32                         // matmul.py:40:32
	elect.sync 	%r449|%p115, -1;
	bfe.u32 	%r450, %r448, 4, 14;
	cvt.u64.u32 	%rd134, %r450;
	or.b64 	%rd117, %rd134, 4611686293372403712;
	mov.b32 	%r431, 135268624;
	// begin inline asm
	@%p115 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd117, %rd118, %r431, %p114;
	// end inline asm
	add.s32 	%r451, %r448, 32;
	bfe.u32 	%r452, %r451, 4, 14;
	cvt.u64.u32 	%rd135, %r452;
	or.b64 	%rd119, %rd135, 4611686293372403712;
	// begin inline asm
	@%p115 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd119, %rd120, %r431, %p114;
	// end inline asm
	add.s32 	%r453, %r448, 64;
	bfe.u32 	%r454, %r453, 4, 14;
	cvt.u64.u32 	%rd136, %r454;
	or.b64 	%rd121, %rd136, 4611686293372403712;
	// begin inline asm
	@%p115 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd121, %rd122, %r431, %p114;
	// end inline asm
	add.s32 	%r455, %r448, 96;
	bfe.u32 	%r456, %r455, 4, 14;
	cvt.u64.u32 	%rd137, %r456;
	or.b64 	%rd123, %rd137, 4611686293372403712;
	// begin inline asm
	@%p115 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd123, %rd124, %r431, %p114;
	// end inline asm
	add.s32 	%r457, %r448, 16384;
	bfe.u32 	%r458, %r457, 4, 14;
	cvt.u64.u32 	%rd138, %r458;
	or.b64 	%rd125, %rd138, 4611686293372403712;
	// begin inline asm
	@%p115 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd125, %rd126, %r431, %p114;
	// end inline asm
	add.s32 	%r459, %r448, 16416;
	bfe.u32 	%r460, %r459, 4, 14;
	cvt.u64.u32 	%rd139, %r460;
	or.b64 	%rd127, %rd139, 4611686293372403712;
	// begin inline asm
	@%p115 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd127, %rd128, %r431, %p114;
	// end inline asm
	add.s32 	%r461, %r448, 16448;
	bfe.u32 	%r462, %r461, 4, 14;
	cvt.u64.u32 	%rd140, %r462;
	or.b64 	%rd129, %rd140, 4611686293372403712;
	// begin inline asm
	@%p115 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd129, %rd130, %r431, %p114;
	// end inline asm
	add.s32 	%r463, %r448, 16480;
	bfe.u32 	%r464, %r463, 4, 14;
	cvt.u64.u32 	%rd141, %r464;
	or.b64 	%rd131, %rd141, 4611686293372403712;
	// begin inline asm
	@%p115 tcgen05.mma.cta_group::1.kind::tf32 [ %r561 + 0 ], %rd131, %rd132, %r431, %p114;
	// end inline asm
	cvt.u64.u32 	%rd133, %r590;
	// begin inline asm
	@%p115 tcgen05.commit.cta_group::1.mbarrier::arrive::one.b64 [%rd133];
	// end inline asm
	bra.uni 	$L__BB0_6;
$L__BB0_7:                              // %._crit_edge
	.loc	1 37 19                         // matmul.py:37:19
	@%p70 bra 	$L__BB0_9;
// %bb.8:
	.loc	1 40 32                         // matmul.py:40:32
	// begin inline asm
	
{
	.reg .pred complete;
	waitLoop:
	mbarrier.try_wait.parity.shared.b64 complete, [%r590], %r591;
	@!complete bra.uni waitLoop;
}

	// end inline asm
$L__BB0_9:
	.loc	1 30 8                          // matmul.py:30:8
	cvta.global.u64 	%rd144, %rd63;
	.loc	1 37 19                         // matmul.py:37:19
	bar.sync 	0;
	// begin inline asm
	@%p145 mbarrier.inval.shared::cta.b64 [%r154];
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p145 mbarrier.inval.shared::cta.b64 [%r155];
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p145 mbarrier.inval.shared::cta.b64 [%r329];
	// end inline asm
	add.s32 	%r491, %r62, 180256;
	// begin inline asm
	@%p145 mbarrier.inval.shared::cta.b64 [%r491];
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p145 mbarrier.inval.shared::cta.b64 [%r153];
	// end inline asm
	.loc	1 40 32                         // matmul.py:40:32
	// begin inline asm
	tcgen05.ld.sync.aligned.32x32b.x64.b32 {%r493, %r494, %r495, %r496, %r497, %r498, %r499, %r500, %r501, %r502, %r503, %r504, %r505, %r506, %r507, %r508, %r509, %r510, %r511, %r512, %r513, %r514, %r515, %r516, %r517, %r518, %r519, %r520, %r521, %r522, %r523, %r524, %r525, %r526, %r527, %r528, %r529, %r530, %r531, %r532, %r533, %r534, %r535, %r536, %r537, %r538, %r539, %r540, %r541, %r542, %r543, %r544, %r545, %r546, %r547, %r548, %r549, %r550, %r551, %r552, %r553, %r554, %r555, %r556}, [%r557 + 0];
	// end inline asm
	// begin inline asm
	tcgen05.wait::ld.sync.aligned;
	// end inline asm
	.loc	1 43 63                         // matmul.py:43:63
	and.b32 	%r563, %r23, 16256;
	or.b32 	%r564, %r563, %r24;
	add.s32 	%r565, %r62, %r564;
	st.shared.v4.b32 	[%r565], {%r493, %r494, %r495, %r496};
	st.shared.v4.b32 	[%r565+16384], {%r525, %r526, %r527, %r528};
	xor.b32 	%r566, %r564, 16;
	add.s32 	%r567, %r62, %r566;
	st.shared.v4.b32 	[%r567], {%r497, %r498, %r499, %r500};
	st.shared.v4.b32 	[%r567+16384], {%r529, %r530, %r531, %r532};
	xor.b32 	%r568, %r564, 32;
	add.s32 	%r569, %r62, %r568;
	st.shared.v4.b32 	[%r569], {%r501, %r502, %r503, %r504};
	st.shared.v4.b32 	[%r569+16384], {%r533, %r534, %r535, %r536};
	xor.b32 	%r570, %r564, 48;
	add.s32 	%r571, %r62, %r570;
	st.shared.v4.b32 	[%r571], {%r505, %r506, %r507, %r508};
	st.shared.v4.b32 	[%r571+16384], {%r537, %r538, %r539, %r540};
	xor.b32 	%r572, %r564, 64;
	add.s32 	%r573, %r62, %r572;
	st.shared.v4.b32 	[%r573], {%r509, %r510, %r511, %r512};
	st.shared.v4.b32 	[%r573+16384], {%r541, %r542, %r543, %r544};
	xor.b32 	%r574, %r564, 80;
	add.s32 	%r575, %r62, %r574;
	st.shared.v4.b32 	[%r575], {%r513, %r514, %r515, %r516};
	st.shared.v4.b32 	[%r575+16384], {%r545, %r546, %r547, %r548};
	xor.b32 	%r576, %r564, 96;
	add.s32 	%r577, %r62, %r576;
	st.shared.v4.b32 	[%r577], {%r517, %r518, %r519, %r520};
	st.shared.v4.b32 	[%r577+16384], {%r549, %r550, %r551, %r552};
	xor.b32 	%r578, %r564, 112;
	add.s32 	%r579, %r62, %r578;
	st.shared.v4.b32 	[%r579], {%r521, %r522, %r523, %r524};
	st.shared.v4.b32 	[%r579+16384], {%r553, %r554, %r555, %r556};
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	bar.sync 	0;
	elect.sync 	%r580|%p153, -1;
	and.pred 	%p150, %p73, %p153;
	// begin inline asm
	@%p150 cp.async.bulk.tensor.2d.global.shared::cta.bulk_group [%rd144, {%r558, %r559}], [%r560];
	// end inline asm
	cp.async.bulk.commit_group;
	cp.async.bulk.wait_group.read 	0;
	bar.sync 	0;
	.loc	1 43 4                          // matmul.py:43:4
	// begin inline asm
	@%p1 tcgen05.dealloc.cta_group::1.sync.aligned.b32 %r561, 64;
	// end inline asm
	ret;
$L__tmp3:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/ubuntu/triton/matmul.py"
	.file	2 "/home/ubuntu/triton/python/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 1                                   // DW_CHILDREN_yes
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 2                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 0                                   // DW_CHILDREN_no
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 32                                  // DW_AT_inline
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 3                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 1                                   // DW_CHILDREN_yes
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 4                                   // Abbreviation Code
.b8 29                                  // DW_TAG_inlined_subroutine
.b8 0                                   // DW_CHILDREN_no
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 88                                  // DW_AT_call_file
.b8 11                                  // DW_FORM_data1
.b8 89                                  // DW_AT_call_line
.b8 11                                  // DW_FORM_data1
.b8 87                                  // DW_AT_call_column
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 136                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x81 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 109                                 // DW_AT_name
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 117
.b8 98
.b8 117
.b8 110
.b8 116
.b8 117
.b8 47
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // Abbrev [2] 0x37:0x26 DW_TAG_subprogram
.b8 109                                 // DW_AT_name
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 95
.b8 109
.b8 97
.b8 107
.b8 101
.b8 95
.b8 116
.b8 101
.b8 110
.b8 115
.b8 111
.b8 114
.b8 95
.b8 100
.b8 101
.b8 115
.b8 99
.b8 105
.b8 112
.b8 116
.b8 111
.b8 114
.b8 0
.b8 1                                   // DW_AT_inline
.b8 3                                   // Abbrev [3] 0x5d:0x2e DW_TAG_subprogram
.b64 $L__func_begin0                    // DW_AT_low_pc
.b64 $L__func_end0                      // DW_AT_high_pc
.b32 55                                 // DW_AT_abstract_origin
.b8 4                                   // Abbrev [4] 0x72:0x18 DW_TAG_inlined_subroutine
.b32 55                                 // DW_AT_abstract_origin
.b64 $L__tmp1                           // DW_AT_low_pc
.b64 $L__tmp2                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 37                                  // DW_AT_call_line
.b8 30                                  // DW_AT_call_column
.b8 0                                   // End Of Children Mark
.b8 0                                   // End Of Children Mark
	}
	.section	.debug_macinfo	{	}
